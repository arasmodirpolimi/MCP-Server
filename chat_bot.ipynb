{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aaa823-c216-4d4f-837e-a88781e90912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mcp in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.12.4)\n",
      "Requirement already satisfied: anyio>=4.5 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mcp) (4.10.0)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mcp) (0.4.1)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mcp) (0.28.1)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mcp) (4.25.1)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mcp) (2.11.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.8.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mcp) (2.11.7)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mcp) (0.0.18)\n",
      "Requirement already satisfied: pywin32>=310 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mcp) (311)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mcp) (2.1.3)\n",
      "Requirement already satisfied: starlette>=0.27 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mcp) (0.46.2)\n",
      "Requirement already satisfied: uvicorn>=0.23.1 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from mcp) (0.29.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.8.0->mcp) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.8.0->mcp) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.8.0->mcp) (4.12.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.8.0->mcp) (0.4.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio>=4.5->mcp) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio>=4.5->mcp) (1.3.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.27->mcp) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.27->mcp) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->mcp) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=4.20.0->mcp) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=4.20.0->mcp) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=4.20.0->mcp) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=4.20.0->mcp) (0.27.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic-settings>=2.5.2->mcp) (1.1.1)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from uvicorn>=0.23.1->mcp) (8.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from click>=7.0->uvicorn>=0.23.1->mcp) (0.4.6)\n",
      "Requirement already satisfied: jupyter-server-proxy in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.4.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server-proxy) (3.12.15)\n",
      "Requirement already satisfied: jupyter-server>=1.24.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server-proxy) (2.17.0)\n",
      "Requirement already satisfied: simpervisor>=1.0.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server-proxy) (1.0.0)\n",
      "Requirement already satisfied: tornado>=6.1.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server-proxy) (6.5.2)\n",
      "Requirement already satisfied: traitlets>=5.1.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server-proxy) (5.14.3)\n",
      "Requirement already satisfied: anyio>=3.1.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (4.10.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (25.1.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (3.1.4)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (5.8.1)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (7.16.6)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (5.10.4)\n",
      "Requirement already satisfied: packaging>=22.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (24.2)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (0.23.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (3.0.2)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (27.1.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (1.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio>=3.1.0->jupyter-server>=1.24.0->jupyter-server-proxy) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio>=3.1.0->jupyter-server>=1.24.0->jupyter-server-proxy) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server>=1.24.0->jupyter-server-proxy) (25.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2>=3.0.3->jupyter-server>=1.24.0->jupyter-server-proxy) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-client>=7.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server>=1.24.0->jupyter-server-proxy) (4.4.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server>=1.24.0->jupyter-server-proxy) (311)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy) (4.25.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy) (4.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy) (6.0.2)\n",
      "Requirement already satisfied: referencing in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy) (0.36.2)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy) (0.1.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=4.18.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=4.18.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy) (2025.9.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=4.18.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy) (0.27.1)\n",
      "Requirement already satisfied: fqdn in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy) (1.1.0)\n",
      "Requirement already satisfied: uri-template in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy) (24.11.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (4.14.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (3.1.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (1.5.1)\n",
      "Requirement already satisfied: pygments>=2.4.1 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (2.19.2)\n",
      "Requirement already satisfied: webencodings in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server>=1.24.0->jupyter-server-proxy) (2.21.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=7.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (1.17.0)\n",
      "Requirement already satisfied: lark>=1.2.2 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp->jupyter-server-proxy) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp->jupyter-server-proxy) (1.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp->jupyter-server-proxy) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp->jupyter-server-proxy) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp->jupyter-server-proxy) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp->jupyter-server-proxy) (1.20.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server>=1.24.0->jupyter-server-proxy) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server>=1.24.0->jupyter-server-proxy) (2.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (4.12.2)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy) (2.9.0.20251008)\n",
      "Requirement already satisfied: openai in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.101.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: nest_asyncio in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: ollama in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ollama) (2.11.7)\n",
      "Requirement already satisfied: anyio in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.27->ollama) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.27->ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.9->ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.9->ollama) (4.12.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.9->ollama) (0.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n",
      "Requirement already satisfied: requests in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arsalan\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arsalan\\Desktop\\MCP_Example\\.venv\\Scripts\\python.exe: No module named pip\n"
     ]
    }
   ],
   "source": [
    "%pip install mcp\n",
    "%pip install jupyter-server-proxy\n",
    "%pip install openai\n",
    "%pip install python-dotenv\n",
    "%pip install nest_asyncio\n",
    "%pip install ollama\n",
    "%pip install requests\n",
    "%pip install langchain langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f96af0c",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "Create a .env file in project root with:\n",
    "\n",
    "OPENWEATHER_API_KEY=YOUR_KEY_HERE\n",
    "OPENWEATHER_BASE_URL=https://api.openweathermap.org/data/2.5/weather\n",
    "OPENAI_API_KEY=YOUR_OPENAI_KEY\n",
    "\n",
    "If only OPEN_AI_API_KEY exists it will be aliased automatically.\n",
    "Restart the kernel after changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a33bbe5-cc79-4e8a-ba37-4633a71a6780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Load variables from .env if present\n",
    "\n",
    "def ensure_env(name: str, default: str | None = None, prompt: bool = True, secret: bool = False) -> str:\n",
    "    val = os.getenv(name)\n",
    "    if val:\n",
    "        return val\n",
    "    if default is not None:\n",
    "        os.environ[name] = default\n",
    "        return default\n",
    "    if prompt:\n",
    "        try:\n",
    "            entered = input(f\"Enter value for {name}: \").strip()\n",
    "            if entered:\n",
    "                os.environ[name] = entered\n",
    "                return entered\n",
    "        except Exception:\n",
    "            pass\n",
    "    raise RuntimeError(f\"{name} is not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53d64e15-5aa2-4834-82b6-c7ad2fbf5bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather(location: str, unit: str = \"celsius\") -> Dict[str, Any]:\n",
    "    \"\"\"Fetch current weather from OpenWeather.\"\"\"\n",
    "    key = ensure_env(\"OPENWEATHER_API_KEY\", prompt=True)\n",
    "    base_url = os.getenv(\"OPENWEATHER_BASE_URL\") or \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "\n",
    "    unit_map = {\"celsius\": \"metric\", \"fahrenheit\": \"imperial\"}\n",
    "    owm_unit = unit_map.get(unit.lower(), \"metric\")\n",
    "    params = {\"q\": location, \"units\": owm_unit, \"appid\": key}\n",
    "    resp = requests.get(base_url, params=params, timeout=15)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    resolved_name = data.get(\"name\") or location\n",
    "    temp = (data.get(\"main\") or {}).get(\"temp\")\n",
    "    weather_list = data.get(\"weather\")\n",
    "    forecast = [w.get(\"description\") for w in weather_list if isinstance(w, dict) and w.get(\"description\")] if isinstance(weather_list, list) else []\n",
    "    return {\n",
    "        \"location\": resolved_name,\n",
    "        \"temperature\": temp,\n",
    "        \"unit\": \"celsius\" if owm_unit == \"metric\" else \"fahrenheit\",\n",
    "        \"forecast\": forecast\n",
    "    }\n",
    "# get_current_weather(\"Milan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9208723d-0851-4cc5-83ba-08b37eb0c72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI tool schemas (JSON Schema)\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get current weather for a location using OpenWeather. Units can be 'celsius' or 'fahrenheit'.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\"type\": \"string\", \"description\": \"City name (optionally with country code)\"},\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"default\": \"celsius\",\n",
    "                        \"description\": \"Temperature unit\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c02a6245-f474-4549-acb3-8192304b7fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map tool names to Python callables\n",
    "mapping_tool_function = {\n",
    "    \"get_current_weather\": get_current_weather\n",
    "}\n",
    "\n",
    "def execute_tool(tool_name: str, tool_args: Dict[str, Any]) -> str:\n",
    "    result = mapping_tool_function[tool_name](**tool_args)\n",
    "    if result is None:\n",
    "        return \"The operation completed but didn't return any results.\"\n",
    "    if isinstance(result, list):\n",
    "        return \", \".join(map(str, result))\n",
    "    if isinstance(result, dict):\n",
    "        return json.dumps(result, indent=2)\n",
    "    return str(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb3e00ae-6aa9-46cb-9dec-11f8320f5e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OpenAI model: gpt-3.5-turbo\n",
      "The current weather in New York is 18.81°C with moderate rain, and in Milan, it is 21.09°C with a clear sky.\n"
     ]
    }
   ],
   "source": [
    "# ----------------- OpenAI chat with tool calling -----------------\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "BASE_OPENAI_URL = os.getenv(\"BASE_OPENAI_URL\", \"https://api.openai.com/v1\")\n",
    "client = OpenAI(api_key=api_key, base_url=BASE_OPENAI_URL)\n",
    "OPENAI_MODEL = \"gpt-3.5-turbo\"\n",
    "print(f\"Using OpenAI model: {OPENAI_MODEL}\")\n",
    "\n",
    "def process_query(query: str) -> None:\n",
    "    messages: List[Dict[str, Any]] = [{\"role\": \"user\", \"content\": query}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",\n",
    "        temperature=0.01\n",
    "    )\n",
    "    while True:\n",
    "        choice = response.choices[0]\n",
    "        msg = choice.message\n",
    "        if msg.tool_calls:\n",
    "            messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": msg.content or \"\",\n",
    "                \"tool_calls\": [tc.model_dump() for tc in msg.tool_calls]\n",
    "            })\n",
    "            for tc in msg.tool_calls:\n",
    "                name = tc.function.name\n",
    "                args = json.loads(tc.function.arguments or \"{}\")\n",
    "                result = execute_tool(name, args)\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tc.id,\n",
    "                    \"content\": result\n",
    "                })\n",
    "            response = client.chat.completions.create(\n",
    "                model=OPENAI_MODEL,\n",
    "                messages=messages,\n",
    "                tools=tools,\n",
    "                tool_choice=\"auto\",\n",
    "                temperature=0.01\n",
    "            )\n",
    "            continue\n",
    "        if msg.content:\n",
    "            print(msg.content)\n",
    "        break\n",
    "    \n",
    "process_query(\"What's the weather like in New York and Milan?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecd4f94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"object\": \"list\",\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"id\": \"gpt-4-0613\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1686588896,\n",
      "      \"owned_by\": \"openai\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1687882411,\n",
      "      \"owned_by\": \"openai\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-3.5-turbo\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1677610602,\n",
      "      \"owned_by\": \"openai\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"sora-2-pro\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1759708663,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-audio-mini-2025-10-06\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1759512137,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-realtime-mini\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1759517133,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-realtime-mini-2025-10-06\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1759517175,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"sora-2\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1759708615,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"davinci-002\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1692634301,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"babbage-002\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1692634615,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-3.5-turbo-instruct\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1692901427,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-3.5-turbo-instruct-0914\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1694122472,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"dall-e-3\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1698785189,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"dall-e-2\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1698798177,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4-1106-preview\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1698957206,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-3.5-turbo-1106\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1698959748,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"tts-1-hd\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1699046015,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"tts-1-1106\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1699053241,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"tts-1-hd-1106\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1699053533,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"text-embedding-3-small\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1705948997,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"text-embedding-3-large\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1705953180,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4-0125-preview\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1706037612,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4-turbo-preview\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1706037777,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-3.5-turbo-0125\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1706048358,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4-turbo\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1712361441,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4-turbo-2024-04-09\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1712601677,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4o\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1715367049,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4o-2024-05-13\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1715368132,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4o-mini-2024-07-18\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1721172717,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4o-mini\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1721172741,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4o-2024-08-06\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1722814719,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"chatgpt-4o-latest\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1723515131,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"o1-mini-2024-09-12\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1725648979,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"o1-mini\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1725649008,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4o-realtime-preview-2024-10-01\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1727131766,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4o-audio-preview-2024-10-01\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1727389042,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4o-audio-preview\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1727460443,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4o-realtime-preview\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1727659998,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"omni-moderation-latest\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1731689265,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"omni-moderation-2024-09-26\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1732734466,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4o-realtime-preview-2024-12-17\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1733945430,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4o-audio-preview-2024-12-17\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1734034239,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4o-mini-realtime-preview-2024-12-17\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1734112601,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4o-mini-audio-preview-2024-12-17\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1734115920,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"o1-2024-12-17\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1734326976,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"o1\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1734375816,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4o-mini-realtime-preview\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1734387380,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4o-mini-audio-preview\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1734387424,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"o3-mini\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1737146383,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"o3-mini-2025-01-31\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1738010200,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4o-2024-11-20\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1739331543,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4o-search-preview-2025-03-11\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1741388170,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4o-search-preview\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1741388720,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4o-mini-search-preview-2025-03-11\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1741390858,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4o-mini-search-preview\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1741391161,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4o-transcribe\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1742068463,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4o-mini-transcribe\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1742068596,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"o1-pro-2025-03-19\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1742251504,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"o1-pro\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1742251791,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4o-mini-tts\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1742403959,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"o3-2025-04-16\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1744133301,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"o4-mini-2025-04-16\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1744133506,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"o3\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1744225308,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"o4-mini\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1744225351,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4.1-2025-04-14\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1744315746,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4.1\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1744316542,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4.1-mini-2025-04-14\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1744317547,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4.1-mini\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1744318173,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4.1-nano-2025-04-14\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1744321025,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4.1-nano\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1744321707,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-image-1\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1745517030,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"codex-mini-latest\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1746673257,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4o-realtime-preview-2025-06-03\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1748907838,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-4o-audio-preview-2025-06-03\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1748908498,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"o4-mini-deep-research\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1749685485,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"o4-mini-deep-research-2025-06-26\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1750866121,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-5-chat-latest\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1754073306,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-5-2025-08-07\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1754075360,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-5\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1754425777,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-5-mini-2025-08-07\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1754425867,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-5-mini\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1754425928,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-5-nano-2025-08-07\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1754426303,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-5-nano\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1754426384,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-audio-2025-08-28\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1756256146,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-realtime\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1756271701,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-realtime-2025-08-28\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1756271773,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-audio\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1756339249,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-5-codex\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1757527818,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-image-1-mini\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1758845821,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-5-pro-2025-10-06\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1759469707,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-5-pro\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1759469822,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-audio-mini\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1759512027,\n",
      "      \"owned_by\": \"system\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"gpt-3.5-turbo-16k\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1683758102,\n",
      "      \"owned_by\": \"openai-internal\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"tts-1\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1681940951,\n",
      "      \"owned_by\": \"openai-internal\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"whisper-1\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1677532384,\n",
      "      \"owned_by\": \"openai-internal\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"text-embedding-ada-002\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1671217299,\n",
      "      \"owned_by\": \"openai-internal\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ft:gpt-3.5-turbo-0125:personal:my-test-model:A6CmnzQZ:ckpt-step-95\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1726042481,\n",
      "      \"owned_by\": \"user-hu2dhj7oyp1dpoznlrnrtyx9\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ft:gpt-3.5-turbo-0125:personal:my-test-model:A6ChQMTs:ckpt-step-95\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1726042148,\n",
      "      \"owned_by\": \"user-hu2dhj7oyp1dpoznlrnrtyx9\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ft:gpt-3.5-turbo-0125:personal:my-test-model:A6ChRTvE:ckpt-step-190\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1726042149,\n",
      "      \"owned_by\": \"user-hu2dhj7oyp1dpoznlrnrtyx9\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ft:gpt-3.5-turbo-0125:personal:my-test-model:A6ChRu7M\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1726042149,\n",
      "      \"owned_by\": \"user-hu2dhj7oyp1dpoznlrnrtyx9\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ft:gpt-3.5-turbo-0125:personal:my-test-model:A6H0pg4f:ckpt-step-95\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1726058728,\n",
      "      \"owned_by\": \"user-hu2dhj7oyp1dpoznlrnrtyx9\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ft:gpt-3.5-turbo-0125:personal:my-test-model:A6H0qVBU:ckpt-step-190\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1726058728,\n",
      "      \"owned_by\": \"user-hu2dhj7oyp1dpoznlrnrtyx9\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ft:gpt-3.5-turbo-0125:personal:my-test-model:A6H0qNVD\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1726058728,\n",
      "      \"owned_by\": \"user-hu2dhj7oyp1dpoznlrnrtyx9\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ft:gpt-3.5-turbo-0125:personal:my-test-model:A6CmoRkI:ckpt-step-190\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1726042482,\n",
      "      \"owned_by\": \"user-hu2dhj7oyp1dpoznlrnrtyx9\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ft:gpt-3.5-turbo-0125:personal:my-test-model:A6CmoFtt\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1726042482,\n",
      "      \"owned_by\": \"user-hu2dhj7oyp1dpoznlrnrtyx9\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "import os\n",
    "!curl -s https://api.openai.com/v1/models -H \"Authorization: Bearer {os.environ['OPENAI_API_KEY']}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b1809b7-db8c-4779-aadd-c703083c01f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nQuery: \").strip()\n",
    "            if query.lower() == \"quit\":\n",
    "                break\n",
    "            process_query(query)\n",
    "            print()\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b02c22eb-60df-42c9-b3d2-8a179d007c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n",
      "Hello! How can I assist you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a79913c-aad4-4438-a103-751d011211f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting weather_server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile weather_server.py\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "import os, json, requests\n",
    "from typing import Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "mcp = FastMCP(\"weather\")\n",
    "def ensure_env(name: str, default: str | None = None) -> str:\n",
    "    val = os.getenv(name)\n",
    "    if val:\n",
    "        return val\n",
    "    if default is not None:\n",
    "        os.environ[name] = default\n",
    "        return default\n",
    "    raise RuntimeError(f\"{name} is not set\")\n",
    "@mcp.tool()\n",
    "def get_current_weather(location: str, unit: str = \"celsius\") -> Dict[str, Any]:\n",
    "    key = ensure_env(\"OPENWEATHER_API_KEY\")\n",
    "    base_url = os.getenv(\"OPENWEATHER_BASE_URL\") or \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "    unit_map = {\"celsius\": \"metric\", \"fahrenheit\": \"imperial\"}\n",
    "    owm_unit = unit_map.get(unit.lower(), \"metric\")\n",
    "    params = {\"q\": location, \"units\": owm_unit, \"appid\": key}\n",
    "    resp = requests.get(base_url, params=params, timeout=15)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    resolved_name = data.get(\"name\") or location\n",
    "    temp = (data.get(\"main\") or {}).get(\"temp\")\n",
    "    weather_list = data.get(\"weather\")\n",
    "    forecast = [w.get(\"description\") for w in weather_list if isinstance(w, dict) and w.get(\"description\")] if isinstance(weather_list, list) else []\n",
    "    return {\n",
    "        \"location\": resolved_name,\n",
    "        \"temperature\": temp,\n",
    "        \"unit\": \"celsius\" if owm_unit == \"metric\" else \"fahrenheit\",\n",
    "        \"forecast\": forecast\n",
    "    }\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport='stdio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd33fd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mcp_chatbot_openai.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mcp_chatbot_openai.py\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from mcp import ClientSession, StdioServerParameters, types\n",
    "from mcp.client.stdio import stdio_client\n",
    "from typing import List, Dict, Any\n",
    "import asyncio, json, os, nest_asyncio\n",
    "load_dotenv()\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def _flatten_tool_content(content_list):\n",
    "    parts = []\n",
    "    for item in content_list:\n",
    "        # TextContent (MCP) typically has .text\n",
    "        text = getattr(item, 'text', None)\n",
    "        if text is not None:\n",
    "            parts.append(text)\n",
    "        elif isinstance(item, dict):\n",
    "            parts.append(json.dumps(item, ensure_ascii=False))\n",
    "        else:\n",
    "            parts.append(str(item))\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "class MCP_ChatBot:\n",
    "    def __init__(self):\n",
    "        self.session: ClientSession | None = None\n",
    "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.available_tools: List[dict] = []\n",
    "\n",
    "    def _openai_tools_from_mcp(self, mcp_tools: List[types.Tool]) -> List[dict]:\n",
    "        out = []\n",
    "        for t in mcp_tools:\n",
    "            out.append({\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": t.name,\n",
    "                    \"description\": t.description or \"\",\n",
    "                    \"parameters\": t.inputSchema or {\"type\": \"object\", \"properties\": {}}\n",
    "                }\n",
    "            })\n",
    "        return out\n",
    "\n",
    "    async def process_query(self, query: str, model: str = \"gpt-3.5-turbo\"):\n",
    "        messages: List[Dict[str, Any]] = [{\"role\": \"user\", \"content\": query}]\n",
    "        while True:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                tools=self.available_tools or None,\n",
    "                tool_choice=\"auto\" if self.available_tools else \"none\",\n",
    "                temperature=0.01\n",
    "            )\n",
    "            msg = response.choices[0].message\n",
    "            if msg.tool_calls:\n",
    "                messages.append({\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": msg.content or \"\",\n",
    "                    \"tool_calls\": [tc.model_dump() for tc in msg.tool_calls]\n",
    "                })\n",
    "                for tc in msg.tool_calls:\n",
    "                    tool_name = tc.function.name\n",
    "                    raw_args = tc.function.arguments\n",
    "                    try:\n",
    "                        args = json.loads(raw_args) if isinstance(raw_args, str) else (raw_args or {})\n",
    "                    except Exception:\n",
    "                        args = {}\n",
    "                    result = await self.session.call_tool(tool_name, arguments=args)\n",
    "                    flattened = _flatten_tool_content(result.content)\n",
    "                    messages.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tc.id,\n",
    "                        \"name\": tool_name,\n",
    "                        \"content\": flattened\n",
    "                    })\n",
    "                continue\n",
    "            if msg.content:\n",
    "                print(msg.content.strip())\n",
    "            break\n",
    "\n",
    "    async def chat_loop(self):\n",
    "        print(\"MCP Chatbot Started. Type your queries or 'quit'.\")\n",
    "        while True:\n",
    "            try:\n",
    "                q = input(\"\\nQuery: \").strip()\n",
    "                if q.lower() == 'quit':\n",
    "                    break\n",
    "                await self.process_query(q)\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "    async def connect_to_server_and_run(self):\n",
    "        server_params = StdioServerParameters(command=\"uv\", args=[\"run\", \"weather_server.py\"], env=None)\n",
    "        async with stdio_client(server_params) as (read, write):\n",
    "            async with ClientSession(read, write) as session:\n",
    "                self.session = session\n",
    "                await session.initialize()\n",
    "                resp = await session.list_tools()\n",
    "                self.available_tools = self._openai_tools_from_mcp(resp.tools)\n",
    "                await self.chat_loop()\n",
    "\n",
    "async def main():\n",
    "    chatbot = MCP_ChatBot()\n",
    "    await chatbot.connect_to_server_and_run()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53610722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mcp_chatbot_openai.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mcp_chatbot_openai.py\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from mcp import ClientSession, StdioServerParameters, types\n",
    "from mcp.client.stdio import stdio_client\n",
    "from typing import List, Dict, TypedDict, Any\n",
    "from contextlib import AsyncExitStack\n",
    "import asyncio, json, os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def _flatten_tool_content(content_list) -> str:\n",
    "    \"\"\"Flatten MCP CallToolResult.content into plain text for OpenAI 'tool' message.\"\"\"\n",
    "    parts = []\n",
    "    if isinstance(content_list, list):\n",
    "        for item in content_list:\n",
    "            # Most MCP content parts have a 'type' and either 'text' or 'data'\n",
    "            t = getattr(item, \"type\", None) or (isinstance(item, dict) and item.get(\"type\"))\n",
    "            if t == \"text\":\n",
    "                txt = getattr(item, \"text\", None) or (isinstance(item, dict) and item.get(\"text\"))\n",
    "                if txt is not None:\n",
    "                    parts.append(str(txt))\n",
    "            elif t in (\"json\", \"object\"):\n",
    "                data = getattr(item, \"data\", None) or (isinstance(item, dict) and (item.get(\"data\") or item.get(\"value\")))\n",
    "                try:\n",
    "                    parts.append(json.dumps(data, ensure_ascii=False))\n",
    "                except Exception:\n",
    "                    parts.append(str(data))\n",
    "            else:\n",
    "                try:\n",
    "                    parts.append(json.dumps(item, default=str, ensure_ascii=False))\n",
    "                except Exception:\n",
    "                    parts.append(str(item))\n",
    "    elif content_list is not None:\n",
    "        if isinstance(content_list, (dict, list)):\n",
    "            parts.append(json.dumps(content_list, ensure_ascii=False))\n",
    "        else:\n",
    "            parts.append(str(content_list))\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "class ToolDefinition(TypedDict):\n",
    "    name: str\n",
    "    description: str\n",
    "    input_schema: dict\n",
    "\n",
    "\n",
    "class MCP_ChatBot:\n",
    "    def __init__(self):\n",
    "        self.client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        self.exit_stack = AsyncExitStack()\n",
    "        self.sessions: List[ClientSession] = []\n",
    "        self.tool_to_session: Dict[str, ClientSession] = {}\n",
    "        self.available_tools: List[ToolDefinition] = []  # OpenAI function-calling schema\n",
    "\n",
    "    def _openai_tools_from_mcp(self, mcp_tools: List[types.Tool]) -> List[dict]:\n",
    "        tools = []\n",
    "        for t in mcp_tools:\n",
    "            tools.append({\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": t.name,\n",
    "                    \"description\": t.description or \"\",\n",
    "                    \"parameters\": t.inputSchema or {\"type\": \"object\", \"properties\": {}},\n",
    "                }\n",
    "            })\n",
    "        return tools\n",
    "\n",
    "    async def connect_to_server(self, server_name: str, server_cfg: dict):\n",
    "        \"\"\"Connect to one MCP server (stdio).\"\"\"\n",
    "        try:\n",
    "            params = StdioServerParameters(**server_cfg)\n",
    "            read, write = await self.exit_stack.enter_async_context(stdio_client(params))\n",
    "            session = await self.exit_stack.enter_async_context(ClientSession(read, write))\n",
    "            await session.initialize()\n",
    "\n",
    "            # Remember the session\n",
    "            self.sessions.append(session)\n",
    "\n",
    "            # Discover tools for this server\n",
    "            resp = await session.list_tools()\n",
    "            tools = resp.tools or []\n",
    "            print(f\"Connected to {server_name} with tools:\", [t.name for t in tools])\n",
    "\n",
    "            # Map tool -> session and add to OpenAI tool list\n",
    "            for t in tools:\n",
    "                self.tool_to_session[t.name] = session\n",
    "            self.available_tools.extend(self._openai_tools_from_mcp(tools))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to connect to {server_name}: {e}\")\n",
    "\n",
    "    async def connect_to_servers(self, config_path: str = \"server_config.json\"):\n",
    "        \"\"\"Read server_config.json and connect to each server.\"\"\"\n",
    "        with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            cfg = json.load(f)\n",
    "        servers = cfg.get(\"mcpServers\", {})\n",
    "        for name, server_cfg in servers.items():\n",
    "            await self.connect_to_server(name, server_cfg)\n",
    "\n",
    "    async def process_query(self, query: str, model: str = \"gpt-3.5-turbo\"):\n",
    "        messages: List[Dict[str, Any]] = [{\"role\": \"user\", \"content\": query}]\n",
    "\n",
    "        while True:\n",
    "            resp = self.client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                tools=self.available_tools or None,\n",
    "                tool_choice=\"auto\" if self.available_tools else \"none\",\n",
    "                temperature=0.1,\n",
    "            )\n",
    "            msg = resp.choices[0].message\n",
    "\n",
    "            # Tool calls?\n",
    "            if msg.tool_calls:\n",
    "                # Keep assistant msg (with tool_calls) in history\n",
    "                messages.append({\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": msg.content or \"\",\n",
    "                    \"tool_calls\": [tc.model_dump() for tc in msg.tool_calls],\n",
    "                })\n",
    "\n",
    "                for tc in msg.tool_calls:\n",
    "                    tool_name = tc.function.name\n",
    "                    raw_args = tc.function.arguments\n",
    "                    try:\n",
    "                        args = json.loads(raw_args) if isinstance(raw_args, str) else (raw_args or {})\n",
    "                    except Exception:\n",
    "                        args = {}\n",
    "\n",
    "                    session = self.tool_to_session.get(tool_name)\n",
    "                    if not session:\n",
    "                        # Unknown tool — tell the model\n",
    "                        messages.append({\n",
    "                            \"role\": \"tool\",\n",
    "                            \"tool_call_id\": tc.id,\n",
    "                            \"name\": tool_name,\n",
    "                            \"content\": f\"Tool '{tool_name}' is not available.\",\n",
    "                        })\n",
    "                        continue\n",
    "\n",
    "                    print(f\"Calling tool {tool_name} with args {args}\")\n",
    "                    result = await session.call_tool(tool_name, arguments=args)\n",
    "                    messages.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tc.id,\n",
    "                        \"name\": tool_name,\n",
    "                        \"content\": _flatten_tool_content(result.content),\n",
    "                    })\n",
    "\n",
    "                # Let the model read tool results and continue\n",
    "                continue\n",
    "\n",
    "            # Final answer (no tool calls)\n",
    "            if msg.content:\n",
    "                print(msg.content.strip())\n",
    "            break\n",
    "\n",
    "    async def chat_loop(self):\n",
    "        print(\"\\nMCP Chatbot (OpenAI) — type your query, or 'quit' to exit.\")\n",
    "        while True:\n",
    "            try:\n",
    "                q = input(\"\\nQuery: \").strip()\n",
    "                if q.lower() == \"quit\":\n",
    "                    break\n",
    "                await self.process_query(q)\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "    async def run(self):\n",
    "        try:\n",
    "            await self.connect_to_servers()\n",
    "            await self.chat_loop()\n",
    "        finally:\n",
    "            await self.exit_stack.aclose()\n",
    "\n",
    "    async def cleanup(self): # new\n",
    "        \"\"\"Cleanly close all resources using AsyncExitStack.\"\"\"\n",
    "        await self.exit_stack.aclose()\n",
    "\n",
    "\n",
    "\n",
    "async def main():\n",
    "    chatbot = MCP_ChatBot()\n",
    "    try:\n",
    "        # the mcp clients and sessions are not initialized using \"with\"\n",
    "        # like in the previous lesson\n",
    "        # so the cleanup should be manually handled\n",
    "        await chatbot.connect_to_servers() # new! \n",
    "        await chatbot.chat_loop()\n",
    "    finally:\n",
    "        await chatbot.cleanup() #new! \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1946ef77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mcp_chatbot.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mcp_chatbot.py\n",
    "from dotenv import load_dotenv\n",
    "from mcp import ClientSession, StdioServerParameters, types\n",
    "from mcp.client.stdio import stdio_client\n",
    "from typing import List, Dict, TypedDict, Any, Optional\n",
    "from contextlib import AsyncExitStack\n",
    "import asyncio, json, os, requests\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ---------------------------\n",
    "# Ollama adapter (no OpenAI)\n",
    "# ---------------------------\n",
    "class OllamaAdapter:\n",
    "    def __init__(self, base: str = \"http://127.0.0.1:11434\"):\n",
    "        self.base = base.rstrip(\"/\")\n",
    "\n",
    "    def chat_once(\n",
    "        self,\n",
    "        model: str,\n",
    "        messages: List[Dict[str, Any]],\n",
    "        temperature: float = 0.1,\n",
    "        tools: Optional[List[dict]] = None,\n",
    "        tool_choice: str | dict | None = \"auto\",\n",
    "    ):\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": messages,\n",
    "            \"stream\": False,\n",
    "            \"options\": {\"temperature\": temperature},\n",
    "        }\n",
    "        if tools:\n",
    "            payload[\"tools\"] = tools\n",
    "        if tool_choice:\n",
    "            payload[\"tool_choice\"] = tool_choice\n",
    "\n",
    "        r = requests.post(f\"{self.base}/api/chat\", json=payload, timeout=120)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        msg = data.get(\"message\", {}) or {}\n",
    "        # Normalize into an OpenAI-like shape the rest of the code expects\n",
    "        return {\n",
    "            \"choices\": [{\n",
    "                \"message\": {\n",
    "                    \"role\": msg.get(\"role\", \"assistant\"),\n",
    "                    \"content\": msg.get(\"content\", \"\"),\n",
    "                    \"tool_calls\": msg.get(\"tool_calls\") or [],\n",
    "                }\n",
    "            }]\n",
    "        }\n",
    "\n",
    "def _flatten_tool_content(content_list) -> str:\n",
    "    parts = []\n",
    "    if isinstance(content_list, list):\n",
    "        for item in content_list:\n",
    "            t = getattr(item, \"type\", None) or (isinstance(item, dict) and item.get(\"type\"))\n",
    "            if t == \"text\":\n",
    "                txt = getattr(item, \"text\", None) or (isinstance(item, dict) and item.get(\"text\"))\n",
    "                if txt is not None:\n",
    "                    parts.append(str(txt))\n",
    "            elif t in (\"json\", \"object\"):\n",
    "                data = getattr(item, \"data\", None) or (isinstance(item, dict) and (item.get(\"data\") or item.get(\"value\")))\n",
    "                try:\n",
    "                    parts.append(json.dumps(data, ensure_ascii=False))\n",
    "                except Exception:\n",
    "                    parts.append(str(data))\n",
    "            else:\n",
    "                try:\n",
    "                    parts.append(json.dumps(item, default=str, ensure_ascii=False))\n",
    "                except Exception:\n",
    "                    parts.append(str(item))\n",
    "    elif content_list is not None:\n",
    "        if isinstance(content_list, (dict, list)):\n",
    "            parts.append(json.dumps(content_list, ensure_ascii=False))\n",
    "        else:\n",
    "            parts.append(str(content_list))\n",
    "    return \"\\n\".join(parts).strip()\n",
    "\n",
    "class ToolDefinition(TypedDict):\n",
    "    name: str\n",
    "    description: str\n",
    "    input_schema: dict\n",
    "\n",
    "class MCP_ChatBot:\n",
    "    def __init__(self):\n",
    "        self.model_default = os.getenv(\"LOCAL_MODEL\", \"qwen2.5:1.5b\")\n",
    "        self.client = OllamaAdapter(os.getenv(\"LOCAL_BASE_URL\", \"http://127.0.0.1:11434\"))\n",
    "        self.exit_stack = AsyncExitStack()\n",
    "        self.sessions: List[ClientSession] = []\n",
    "        self.tool_to_session: Dict[str, ClientSession] = {}\n",
    "        self.available_tools: List[ToolDefinition] = []\n",
    "\n",
    "    def _openai_tools_from_mcp(self, mcp_tools: List[types.Tool]) -> List[dict]:\n",
    "        out = []\n",
    "        for t in mcp_tools:\n",
    "            out.append({\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": t.name,\n",
    "                    \"description\": t.description or \"\",\n",
    "                    \"parameters\": t.inputSchema or {\"type\": \"object\", \"properties\": {}},\n",
    "                }\n",
    "            })\n",
    "        return out\n",
    "\n",
    "    async def _call_mcp_tool(self, tool_name: str, args: dict) -> Optional[str]:\n",
    "        session = self.tool_to_session.get(tool_name)\n",
    "        if not session:\n",
    "            return f\"Tool '{tool_name}' is not registered.\"\n",
    "        try:\n",
    "            result = await session.call_tool(tool_name, arguments=args or {})\n",
    "            return _flatten_tool_content(result.content) or \"(empty result)\"\n",
    "        except Exception as e:\n",
    "            return f\"Tool '{tool_name}' failed: {e}\"\n",
    "\n",
    "    async def connect_to_server(self, server_name: str, server_cfg: dict):\n",
    "        \"\"\"Connect to one MCP server (stdio).\"\"\"\n",
    "        try:\n",
    "            params = StdioServerParameters(**server_cfg)\n",
    "            read, write = await self.exit_stack.enter_async_context(stdio_client(params))\n",
    "            session = await self.exit_stack.enter_async_context(ClientSession(read, write))\n",
    "            await session.initialize()\n",
    "\n",
    "            self.sessions.append(session)\n",
    "\n",
    "            resp = await session.list_tools()\n",
    "            tools = resp.tools or []\n",
    "            print(f\"Connected to {server_name} with tools:\", [t.name for t in tools])\n",
    "\n",
    "            for t in tools:\n",
    "                self.tool_to_session[t.name] = session\n",
    "            self.available_tools.extend(self._openai_tools_from_mcp(tools))\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to connect to {server_name}: {e}\")\n",
    "\n",
    "    async def connect_to_servers(self, config_path: str = \"server_config.json\"):\n",
    "        \"\"\"Read server_config.json and connect to each server.\"\"\"\n",
    "        if not os.path.exists(config_path):\n",
    "            print(f\"No {config_path} found — skipping MCP server connections.\")\n",
    "            return\n",
    "        try:\n",
    "            with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                cfg = json.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read {config_path}: {e}\")\n",
    "            return\n",
    "\n",
    "        for name, server_cfg in (cfg.get(\"mcpServers\", {}) or {}).items():\n",
    "            await self.connect_to_server(name, server_cfg)\n",
    "\n",
    "    async def process_query(self, query: str, model: Optional[str] = None):\n",
    "        model = model or self.model_default\n",
    "\n",
    "        system_preamble = None\n",
    "        if self.available_tools:\n",
    "            tool_names = [t['function']['name'] for t in self.available_tools]\n",
    "            system_preamble = {\n",
    "                'role': 'system',\n",
    "                'content': 'You can call functions to satisfy user requests. Available tools: ' + ', '.join(tool_names)\n",
    "            }\n",
    "\n",
    "        messages: List[Dict[str, Any]] = []\n",
    "        if system_preamble:\n",
    "            messages.append(system_preamble)\n",
    "        messages.append({'role': 'user', 'content': query})\n",
    "\n",
    "        # Run a full tool loop until the model stops calling tools\n",
    "        while True:\n",
    "            resp = self.client.chat_once(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                temperature=0.1,\n",
    "                tools=self.available_tools or None,\n",
    "                tool_choice='auto' if self.available_tools else 'none',\n",
    "            )\n",
    "            msg = resp['choices'][0]['message']\n",
    "            tool_calls = msg.get('tool_calls') or []\n",
    "\n",
    "            # If the model wants to call tools, do them and continue\n",
    "            if tool_calls:\n",
    "                # Keep the assistant step (with tool_calls) in the transcript\n",
    "                messages.append({\n",
    "                    'role': msg.get('role', 'assistant'),\n",
    "                    'content': msg.get('content', '') or \"\",\n",
    "                    'tool_calls': tool_calls,\n",
    "                })\n",
    "\n",
    "                for tc in tool_calls:\n",
    "                    fn = tc.get('function', {}) or {}\n",
    "                    name = fn.get('name')\n",
    "                    if not name:\n",
    "                        continue\n",
    "                    raw_args = fn.get('arguments') or '{}'\n",
    "                    try:\n",
    "                        args = json.loads(raw_args) if isinstance(raw_args, str) else (raw_args or {})\n",
    "                    except Exception:\n",
    "                        args = {}\n",
    "\n",
    "                    result_text = await self._call_mcp_tool(name, args)\n",
    "\n",
    "                    messages.append({\n",
    "                        'role': 'tool',\n",
    "                        'tool_call_id': tc.get('id') or name,  # Ollama may omit id\n",
    "                        'name': name,\n",
    "                        'content': result_text,\n",
    "                    })\n",
    "\n",
    "                # Let the model see tool outputs and possibly call more tools\n",
    "                continue\n",
    "\n",
    "            # No more tool calls — print final content if present and exit\n",
    "            if msg.get('content'):\n",
    "                print(msg['content'].strip())\n",
    "            break\n",
    "\n",
    "    async def chat_loop(self):\n",
    "        print(\"\\nLocal MCP Chatbot (Ollama) — type your query, or 'quit' to exit.\")\n",
    "        while True:\n",
    "            try:\n",
    "                q = input(\"\\nQuery: \").strip()\n",
    "                if not q:\n",
    "                    continue\n",
    "                if q.lower() in (\"quit\", \"exit\"):\n",
    "                    break\n",
    "                await self.process_query(q)\n",
    "            except (EOFError, KeyboardInterrupt):\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "    async def cleanup(self):\n",
    "        # Ensure all sessions and the stdio pipes are closed\n",
    "        try:\n",
    "            await self.exit_stack.aclose()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "async def main():\n",
    "    bot = MCP_ChatBot()\n",
    "    try:\n",
    "        await bot.connect_to_servers()  # discover and register tools\n",
    "        await bot.chat_loop()\n",
    "    finally:\n",
    "        await bot.cleanup()\n",
    "\n",
    "# Safe runner: works in normal terminals and in environments with an active event loop\n",
    "def _run_async(coro):\n",
    "    try:\n",
    "        loop = asyncio.get_running_loop()\n",
    "    except RuntimeError:\n",
    "        return asyncio.run(coro)\n",
    "    else:\n",
    "        return asyncio.create_task(coro)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    _run_async(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05210c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client\n",
    "client = Client(host=\"http://127.0.0.1:11434\")\n",
    "\n",
    "# Non-streaming\n",
    "res = client.chat(model=\"deepseek-r1:1.5b\",\n",
    "                  messages=[{\"role\":\"user\",\"content\":\"Hello from the Ollama client.\"}])\n",
    "print(res[\"message\"][\"content\"])\n",
    "\n",
    "# Streaming\n",
    "for part in client.chat(model=\"deepseek-r1:1.5b\",\n",
    "                        messages=[{\"role\":\"user\",\"content\":\"Stream, please.\"}],\n",
    "                        stream=True):\n",
    "    print(part[\"message\"][\"content\"], end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339ad949",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MCP_Example",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
