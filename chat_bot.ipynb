{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7aaa823-c216-4d4f-837e-a88781e90912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mcp in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (1.12.4)\n",
      "Requirement already satisfied: anyio>=4.5 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from mcp) (4.11.0)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from mcp) (0.4.1)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from mcp) (0.28.1)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from mcp) (4.23.0)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from mcp) (2.11.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.8.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from mcp) (2.11.9)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from mcp) (0.0.18)\n",
      "Requirement already satisfied: pywin32>=310 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from mcp) (311)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from mcp) (3.0.2)\n",
      "Requirement already satisfied: starlette>=0.27 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from mcp) (0.46.2)\n",
      "Requirement already satisfied: uvicorn>=0.23.1 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from mcp) (0.29.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from anyio>=4.5->mcp) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from anyio>=4.5->mcp) (1.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from anyio>=4.5->mcp) (4.15.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from httpx>=0.27->mcp) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from httpx>=0.27->mcp) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->mcp) (0.14.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jsonschema>=4.20.0->mcp) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jsonschema>=4.20.0->mcp) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jsonschema>=4.20.0->mcp) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jsonschema>=4.20.0->mcp) (0.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.8.0->mcp) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.8.0->mcp) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.8.0->mcp) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from pydantic-settings>=2.5.2->mcp) (0.21.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from uvicorn>=0.23.1->mcp) (8.1.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from click>=7.0->uvicorn>=0.23.1->mcp) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: jupyter-server-proxy in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (4.4.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-server-proxy) (3.10.5)\n",
      "Requirement already satisfied: jupyter-server>=1.24.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-server-proxy) (2.14.1)\n",
      "Requirement already satisfied: simpervisor>=1.0.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-server-proxy) (1.0.0)\n",
      "Requirement already satisfied: tornado>=6.1.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-server-proxy) (6.4.1)\n",
      "Requirement already satisfied: traitlets>=5.1.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-server-proxy) (5.14.3)\n",
      "Requirement already satisfied: anyio>=3.1.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (4.11.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (21.3.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (3.1.4)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (5.7.2)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (0.4.4)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (7.16.4)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (7.4.0)\n",
      "Requirement already satisfied: packaging>=22.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (24.1)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (0.14.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (2.0.10)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (25.1.2)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (0.17.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy) (1.8.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from aiohttp->jupyter-server-proxy) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from aiohttp->jupyter-server-proxy) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from aiohttp->jupyter-server-proxy) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from aiohttp->jupyter-server-proxy) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from aiohttp->jupyter-server-proxy) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from aiohttp->jupyter-server-proxy) (1.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from anyio>=3.1.0->jupyter-server>=1.24.0->jupyter-server-proxy) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from anyio>=3.1.0->jupyter-server>=1.24.0->jupyter-server-proxy) (1.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from anyio>=3.1.0->jupyter-server>=1.24.0->jupyter-server-proxy) (4.15.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server>=1.24.0->jupyter-server-proxy) (21.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jinja2>=3.0.3->jupyter-server>=1.24.0->jupyter-server-proxy) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-client>=7.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server>=1.24.0->jupyter-server-proxy) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server>=1.24.0->jupyter-server-proxy) (311)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.24.0->jupyter-server-proxy) (4.23.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server>=1.24.0->jupyter-server-proxy) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server>=1.24.0->jupyter-server-proxy) (6.0.1)\n",
      "Requirement already satisfied: referencing in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server>=1.24.0->jupyter-server-proxy) (0.30.2)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server>=1.24.0->jupyter-server-proxy) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server>=1.24.0->jupyter-server-proxy) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (0.1.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (0.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (1.5.0)\n",
      "Requirement already satisfied: pygments>=2.4.1 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (2.15.1)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server>=1.24.0->jupyter-server-proxy) (2.16.2)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (0.5.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jsonschema>=4.18.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.24.0->jupyter-server-proxy) (2023.7.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jsonschema>=4.18.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.24.0->jupyter-server-proxy) (0.10.6)\n",
      "Requirement already satisfied: fqdn in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.24.0->jupyter-server-proxy) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.24.0->jupyter-server-proxy) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.24.0->jupyter-server-proxy) (2.1)\n",
      "Requirement already satisfied: uri-template in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.24.0->jupyter-server-proxy) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.24.0->jupyter-server-proxy) (24.11.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server>=1.24.0->jupyter-server-proxy) (1.17.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy) (2.5)\n",
      "Requirement already satisfied: pycparser in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server>=1.24.0->jupyter-server-proxy) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.24.0->jupyter-server-proxy) (1.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openai in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (1.109.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from openai) (0.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from openai) (2.11.9)\n",
      "Requirement already satisfied: sniffio in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nest_asyncio in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (1.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mcp\n",
    "%pip install jupyter-server-proxy\n",
    "%pip install openai\n",
    "%pip install python-dotenv\n",
    "%pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f96af0c",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "Create a .env file in project root with:\n",
    "\n",
    "OPENWEATHER_API_KEY=YOUR_KEY_HERE\n",
    "OPENWEATHER_BASE_URL=https://api.openweathermap.org/data/2.5/weather\n",
    "OPENAI_API_KEY=YOUR_OPENAI_KEY\n",
    "\n",
    "If only OPEN_AI_API_KEY exists it will be aliased automatically.\n",
    "Restart the kernel after changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a33bbe5-cc79-4e8a-ba37-4633a71a6780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Load variables from .env if present\n",
    "\n",
    "def ensure_env(name: str, default: str | None = None, prompt: bool = True, secret: bool = False) -> str:\n",
    "    val = os.getenv(name)\n",
    "    if val:\n",
    "        return val\n",
    "    if default is not None:\n",
    "        os.environ[name] = default\n",
    "        return default\n",
    "    if prompt:\n",
    "        try:\n",
    "            entered = input(f\"Enter value for {name}: \").strip()\n",
    "            if entered:\n",
    "                os.environ[name] = entered\n",
    "                return entered\n",
    "        except Exception:\n",
    "            pass\n",
    "    raise RuntimeError(f\"{name} is not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53d64e15-5aa2-4834-82b6-c7ad2fbf5bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather(location: str, unit: str = \"celsius\") -> Dict[str, Any]:\n",
    "    \"\"\"Fetch current weather from OpenWeather.\"\"\"\n",
    "    key = ensure_env(\"OPENWEATHER_API_KEY\", prompt=True)\n",
    "    base_url = os.getenv(\"OPENWEATHER_BASE_URL\") or \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "\n",
    "    unit_map = {\"celsius\": \"metric\", \"fahrenheit\": \"imperial\"}\n",
    "    owm_unit = unit_map.get(unit.lower(), \"metric\")\n",
    "    params = {\"q\": location, \"units\": owm_unit, \"appid\": key}\n",
    "    resp = requests.get(base_url, params=params, timeout=15)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    resolved_name = data.get(\"name\") or location\n",
    "    temp = (data.get(\"main\") or {}).get(\"temp\")\n",
    "    weather_list = data.get(\"weather\")\n",
    "    forecast = [w.get(\"description\") for w in weather_list if isinstance(w, dict) and w.get(\"description\")] if isinstance(weather_list, list) else []\n",
    "    return {\n",
    "        \"location\": resolved_name,\n",
    "        \"temperature\": temp,\n",
    "        \"unit\": \"celsius\" if owm_unit == \"metric\" else \"fahrenheit\",\n",
    "        \"forecast\": forecast\n",
    "    }\n",
    "# get_current_weather(\"Milan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9208723d-0851-4cc5-83ba-08b37eb0c72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI tool schemas (JSON Schema)\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get current weather for a location using OpenWeather. Units can be 'celsius' or 'fahrenheit'.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\"type\": \"string\", \"description\": \"City name (optionally with country code)\"},\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"default\": \"celsius\",\n",
    "                        \"description\": \"Temperature unit\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c02a6245-f474-4549-acb3-8192304b7fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map tool names to Python callables\n",
    "mapping_tool_function = {\n",
    "    \"get_current_weather\": get_current_weather\n",
    "}\n",
    "\n",
    "def execute_tool(tool_name: str, tool_args: Dict[str, Any]) -> str:\n",
    "    result = mapping_tool_function[tool_name](**tool_args)\n",
    "    if result is None:\n",
    "        return \"The operation completed but didn't return any results.\"\n",
    "    if isinstance(result, list):\n",
    "        return \", \".join(map(str, result))\n",
    "    if isinstance(result, dict):\n",
    "        return json.dumps(result, indent=2)\n",
    "    return str(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3e00ae-6aa9-46cb-9dec-11f8320f5e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- OpenAI chat with tool calling -----------------\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-3.5-turbo\")\n",
    "print(f\"Using OpenAI model: {OPENAI_MODEL}\")\n",
    "\n",
    "def process_query(query: str) -> None:\n",
    "    messages: List[Dict[str, Any]] = [{\"role\": \"user\", \"content\": query}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",\n",
    "        temperature=0.01\n",
    "    )\n",
    "    while True:\n",
    "        choice = response.choices[0]\n",
    "        msg = choice.message\n",
    "        if msg.tool_calls:\n",
    "            messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": msg.content or \"\",\n",
    "                \"tool_calls\": [tc.model_dump() for tc in msg.tool_calls]\n",
    "            })\n",
    "            for tc in msg.tool_calls:\n",
    "                name = tc.function.name\n",
    "                args = json.loads(tc.function.arguments or \"{}\")\n",
    "                result = execute_tool(name, args)\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tc.id,\n",
    "                    \"content\": result\n",
    "                })\n",
    "            response = client.chat.completions.create(\n",
    "                model=OPENAI_MODEL,\n",
    "                messages=messages,\n",
    "                tools=tools,\n",
    "                tool_choice=\"auto\",\n",
    "                temperature=0.01\n",
    "            )\n",
    "            continue\n",
    "        if msg.content:\n",
    "            print(msg.content)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b1809b7-db8c-4779-aadd-c703083c01f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nQuery: \").strip()\n",
    "            if query.lower() == \"quit\":\n",
    "                break\n",
    "            process_query(query)\n",
    "            print()\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b02c22eb-60df-42c9-b3d2-8a179d007c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n",
      "\n",
      "Error: Connection error.\n"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a79913c-aad4-4438-a103-751d011211f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting weather_server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile weather_server.py\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "import os, json, requests\n",
    "from typing import Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "mcp = FastMCP(\"weather\")\n",
    "def ensure_env(name: str, default: str | None = None) -> str:\n",
    "    val = os.getenv(name)\n",
    "    if val:\n",
    "        return val\n",
    "    if default is not None:\n",
    "        os.environ[name] = default\n",
    "        return default\n",
    "    raise RuntimeError(f\"{name} is not set\")\n",
    "@mcp.tool()\n",
    "def get_current_weather(location: str, unit: str = \"celsius\") -> Dict[str, Any]:\n",
    "    key = ensure_env(\"OPENWEATHER_API_KEY\")\n",
    "    base_url = os.getenv(\"OPENWEATHER_BASE_URL\") or \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "    unit_map = {\"celsius\": \"metric\", \"fahrenheit\": \"imperial\"}\n",
    "    owm_unit = unit_map.get(unit.lower(), \"metric\")\n",
    "    params = {\"q\": location, \"units\": owm_unit, \"appid\": key}\n",
    "    resp = requests.get(base_url, params=params, timeout=15)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    resolved_name = data.get(\"name\") or location\n",
    "    temp = (data.get(\"main\") or {}).get(\"temp\")\n",
    "    weather_list = data.get(\"weather\")\n",
    "    forecast = [w.get(\"description\") for w in weather_list if isinstance(w, dict) and w.get(\"description\")] if isinstance(weather_list, list) else []\n",
    "    return {\n",
    "        \"location\": resolved_name,\n",
    "        \"temperature\": temp,\n",
    "        \"unit\": \"celsius\" if owm_unit == \"metric\" else \"fahrenheit\",\n",
    "        \"forecast\": forecast\n",
    "    }\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport='stdio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd33fd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mcp_chatbot.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mcp_chatbot.py\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from mcp import ClientSession, StdioServerParameters, types\n",
    "from mcp.client.stdio import stdio_client\n",
    "from typing import List, Dict, Any\n",
    "import asyncio, json, os, nest_asyncio\n",
    "load_dotenv()\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def _flatten_tool_content(content_list):\n",
    "    parts = []\n",
    "    for item in content_list:\n",
    "        # TextContent (MCP) typically has .text\n",
    "        text = getattr(item, 'text', None)\n",
    "        if text is not None:\n",
    "            parts.append(text)\n",
    "        elif isinstance(item, dict):\n",
    "            parts.append(json.dumps(item, ensure_ascii=False))\n",
    "        else:\n",
    "            parts.append(str(item))\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "class MCP_ChatBot:\n",
    "    def __init__(self):\n",
    "        self.session: ClientSession | None = None\n",
    "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.available_tools: List[dict] = []\n",
    "\n",
    "    def _openai_tools_from_mcp(self, mcp_tools: List[types.Tool]) -> List[dict]:\n",
    "        out = []\n",
    "        for t in mcp_tools:\n",
    "            out.append({\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": t.name,\n",
    "                    \"description\": t.description or \"\",\n",
    "                    \"parameters\": t.inputSchema or {\"type\": \"object\", \"properties\": {}}\n",
    "                }\n",
    "            })\n",
    "        return out\n",
    "\n",
    "    async def process_query(self, query: str, model: str = \"gpt-3.5-turbo\"):\n",
    "        messages: List[Dict[str, Any]] = [{\"role\": \"user\", \"content\": query}]\n",
    "        while True:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                tools=self.available_tools or None,\n",
    "                tool_choice=\"auto\" if self.available_tools else \"none\",\n",
    "                temperature=0.01\n",
    "            )\n",
    "            msg = response.choices[0].message\n",
    "            if msg.tool_calls:\n",
    "                messages.append({\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": msg.content or \"\",\n",
    "                    \"tool_calls\": [tc.model_dump() for tc in msg.tool_calls]\n",
    "                })\n",
    "                for tc in msg.tool_calls:\n",
    "                    tool_name = tc.function.name\n",
    "                    raw_args = tc.function.arguments\n",
    "                    try:\n",
    "                        args = json.loads(raw_args) if isinstance(raw_args, str) else (raw_args or {})\n",
    "                    except Exception:\n",
    "                        args = {}\n",
    "                    result = await self.session.call_tool(tool_name, arguments=args)\n",
    "                    flattened = _flatten_tool_content(result.content)\n",
    "                    messages.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tc.id,\n",
    "                        \"name\": tool_name,\n",
    "                        \"content\": flattened\n",
    "                    })\n",
    "                continue\n",
    "            if msg.content:\n",
    "                print(msg.content.strip())\n",
    "            break\n",
    "\n",
    "    async def chat_loop(self):\n",
    "        print(\"MCP Chatbot Started. Type your queries or 'quit'.\")\n",
    "        while True:\n",
    "            try:\n",
    "                q = input(\"\\nQuery: \").strip()\n",
    "                if q.lower() == 'quit':\n",
    "                    break\n",
    "                await self.process_query(q)\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "    async def connect_to_server_and_run(self):\n",
    "        server_params = StdioServerParameters(command=\"uv\", args=[\"run\", \"weather_server.py\"], env=None)\n",
    "        async with stdio_client(server_params) as (read, write):\n",
    "            async with ClientSession(read, write) as session:\n",
    "                self.session = session\n",
    "                await session.initialize()\n",
    "                resp = await session.list_tools()\n",
    "                self.available_tools = self._openai_tools_from_mcp(resp.tools)\n",
    "                await self.chat_loop()\n",
    "\n",
    "async def main():\n",
    "    chatbot = MCP_ChatBot()\n",
    "    await chatbot.connect_to_server_and_run()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53610722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mcp_chatbot.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mcp_chatbot.py\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from mcp import ClientSession, StdioServerParameters, types\n",
    "from mcp.client.stdio import stdio_client\n",
    "from typing import List, Dict, TypedDict, Any\n",
    "from contextlib import AsyncExitStack\n",
    "import asyncio, json, os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def _flatten_tool_content(content_list) -> str:\n",
    "    \"\"\"Flatten MCP CallToolResult.content into plain text for OpenAI 'tool' message.\"\"\"\n",
    "    parts = []\n",
    "    if isinstance(content_list, list):\n",
    "        for item in content_list:\n",
    "            # Most MCP content parts have a 'type' and either 'text' or 'data'\n",
    "            t = getattr(item, \"type\", None) or (isinstance(item, dict) and item.get(\"type\"))\n",
    "            if t == \"text\":\n",
    "                txt = getattr(item, \"text\", None) or (isinstance(item, dict) and item.get(\"text\"))\n",
    "                if txt is not None:\n",
    "                    parts.append(str(txt))\n",
    "            elif t in (\"json\", \"object\"):\n",
    "                data = getattr(item, \"data\", None) or (isinstance(item, dict) and (item.get(\"data\") or item.get(\"value\")))\n",
    "                try:\n",
    "                    parts.append(json.dumps(data, ensure_ascii=False))\n",
    "                except Exception:\n",
    "                    parts.append(str(data))\n",
    "            else:\n",
    "                try:\n",
    "                    parts.append(json.dumps(item, default=str, ensure_ascii=False))\n",
    "                except Exception:\n",
    "                    parts.append(str(item))\n",
    "    elif content_list is not None:\n",
    "        if isinstance(content_list, (dict, list)):\n",
    "            parts.append(json.dumps(content_list, ensure_ascii=False))\n",
    "        else:\n",
    "            parts.append(str(content_list))\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "class ToolDefinition(TypedDict):\n",
    "    name: str\n",
    "    description: str\n",
    "    input_schema: dict\n",
    "\n",
    "\n",
    "class MCP_ChatBot:\n",
    "    def __init__(self):\n",
    "        self.client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        self.exit_stack = AsyncExitStack()\n",
    "        self.sessions: List[ClientSession] = []\n",
    "        self.tool_to_session: Dict[str, ClientSession] = {}\n",
    "        self.available_tools: List[ToolDefinition] = []  # OpenAI function-calling schema\n",
    "\n",
    "    def _openai_tools_from_mcp(self, mcp_tools: List[types.Tool]) -> List[dict]:\n",
    "        tools = []\n",
    "        for t in mcp_tools:\n",
    "            tools.append({\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": t.name,\n",
    "                    \"description\": t.description or \"\",\n",
    "                    \"parameters\": t.inputSchema or {\"type\": \"object\", \"properties\": {}},\n",
    "                }\n",
    "            })\n",
    "        return tools\n",
    "\n",
    "    async def connect_to_server(self, server_name: str, server_cfg: dict):\n",
    "        \"\"\"Connect to one MCP server (stdio).\"\"\"\n",
    "        try:\n",
    "            params = StdioServerParameters(**server_cfg)\n",
    "            read, write = await self.exit_stack.enter_async_context(stdio_client(params))\n",
    "            session = await self.exit_stack.enter_async_context(ClientSession(read, write))\n",
    "            await session.initialize()\n",
    "\n",
    "            # Remember the session\n",
    "            self.sessions.append(session)\n",
    "\n",
    "            # Discover tools for this server\n",
    "            resp = await session.list_tools()\n",
    "            tools = resp.tools or []\n",
    "            print(f\"Connected to {server_name} with tools:\", [t.name for t in tools])\n",
    "\n",
    "            # Map tool -> session and add to OpenAI tool list\n",
    "            for t in tools:\n",
    "                self.tool_to_session[t.name] = session\n",
    "            self.available_tools.extend(self._openai_tools_from_mcp(tools))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to connect to {server_name}: {e}\")\n",
    "\n",
    "    async def connect_to_servers(self, config_path: str = \"server_config.json\"):\n",
    "        \"\"\"Read server_config.json and connect to each server.\"\"\"\n",
    "        with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            cfg = json.load(f)\n",
    "        servers = cfg.get(\"mcpServers\", {})\n",
    "        for name, server_cfg in servers.items():\n",
    "            await self.connect_to_server(name, server_cfg)\n",
    "\n",
    "    async def process_query(self, query: str, model: str = \"gpt-3.5-turbo\"):\n",
    "        messages: List[Dict[str, Any]] = [{\"role\": \"user\", \"content\": query}]\n",
    "\n",
    "        while True:\n",
    "            resp = self.client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                tools=self.available_tools or None,\n",
    "                tool_choice=\"auto\" if self.available_tools else \"none\",\n",
    "                temperature=0.1,\n",
    "            )\n",
    "            msg = resp.choices[0].message\n",
    "\n",
    "            # Tool calls?\n",
    "            if msg.tool_calls:\n",
    "                # Keep assistant msg (with tool_calls) in history\n",
    "                messages.append({\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": msg.content or \"\",\n",
    "                    \"tool_calls\": [tc.model_dump() for tc in msg.tool_calls],\n",
    "                })\n",
    "\n",
    "                for tc in msg.tool_calls:\n",
    "                    tool_name = tc.function.name\n",
    "                    raw_args = tc.function.arguments\n",
    "                    try:\n",
    "                        args = json.loads(raw_args) if isinstance(raw_args, str) else (raw_args or {})\n",
    "                    except Exception:\n",
    "                        args = {}\n",
    "\n",
    "                    session = self.tool_to_session.get(tool_name)\n",
    "                    if not session:\n",
    "                        # Unknown tool — tell the model\n",
    "                        messages.append({\n",
    "                            \"role\": \"tool\",\n",
    "                            \"tool_call_id\": tc.id,\n",
    "                            \"name\": tool_name,\n",
    "                            \"content\": f\"Tool '{tool_name}' is not available.\",\n",
    "                        })\n",
    "                        continue\n",
    "\n",
    "                    print(f\"Calling tool {tool_name} with args {args}\")\n",
    "                    result = await session.call_tool(tool_name, arguments=args)\n",
    "                    messages.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tc.id,\n",
    "                        \"name\": tool_name,\n",
    "                        \"content\": _flatten_tool_content(result.content),\n",
    "                    })\n",
    "\n",
    "                # Let the model read tool results and continue\n",
    "                continue\n",
    "\n",
    "            # Final answer (no tool calls)\n",
    "            if msg.content:\n",
    "                print(msg.content.strip())\n",
    "            break\n",
    "\n",
    "    async def chat_loop(self):\n",
    "        print(\"\\nMCP Chatbot (OpenAI) — type your query, or 'quit' to exit.\")\n",
    "        while True:\n",
    "            try:\n",
    "                q = input(\"\\nQuery: \").strip()\n",
    "                if q.lower() == \"quit\":\n",
    "                    break\n",
    "                await self.process_query(q)\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "    async def run(self):\n",
    "        try:\n",
    "            await self.connect_to_servers()\n",
    "            await self.chat_loop()\n",
    "        finally:\n",
    "            await self.exit_stack.aclose()\n",
    "            \n",
    "    async def cleanup(self): # new\n",
    "        \"\"\"Cleanly close all resources using AsyncExitStack.\"\"\"\n",
    "        await self.exit_stack.aclose()\n",
    "\n",
    "\n",
    "\n",
    "async def main():\n",
    "    chatbot = MCP_ChatBot()\n",
    "    try:\n",
    "        # the mcp clients and sessions are not initialized using \"with\"\n",
    "        # like in the previous lesson\n",
    "        # so the cleanup should be manually handled\n",
    "        await chatbot.connect_to_servers() # new! \n",
    "        await chatbot.chat_loop()\n",
    "    finally:\n",
    "        await chatbot.cleanup() #new! \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d36c372f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: litellm[proxy] in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (1.77.5)\n",
      "Requirement already satisfied: PyJWT<3.0.0,>=2.8.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (2.8.0)\n",
      "Requirement already satisfied: aiohttp>=3.10 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (3.10.5)\n",
      "Requirement already satisfied: apscheduler<4.0.0,>=3.10.4 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (3.11.0)\n",
      "Requirement already satisfied: azure-identity<2.0.0,>=1.15.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (1.25.0)\n",
      "Requirement already satisfied: azure-storage-blob<13.0.0,>=12.25.1 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (12.26.0)\n",
      "Requirement already satisfied: backoff in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (2.2.1)\n",
      "Requirement already satisfied: boto3==1.36.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (1.36.0)\n",
      "Requirement already satisfied: click in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (8.1.7)\n",
      "Requirement already satisfied: cryptography in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (43.0.0)\n",
      "Requirement already satisfied: fastapi<0.116.0,>=0.115.5 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (0.115.14)\n",
      "Requirement already satisfied: fastapi-sso<0.17.0,>=0.16.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (0.16.0)\n",
      "Requirement already satisfied: fastuuid>=0.13.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (0.13.5)\n",
      "Requirement already satisfied: gunicorn<24.0.0,>=23.0.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (23.0.0)\n",
      "Requirement already satisfied: httpx>=0.23.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (0.28.1)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (7.0.1)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (3.1.4)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (4.23.0)\n",
      "Requirement already satisfied: litellm-enterprise==0.1.20 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (0.1.20)\n",
      "Requirement already satisfied: litellm-proxy-extras==0.2.22 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (0.2.22)\n",
      "Requirement already satisfied: mcp<2.0.0,>=1.10.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (1.12.4)\n",
      "Requirement already satisfied: openai>=1.99.5 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (1.109.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.7 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (3.11.3)\n",
      "Requirement already satisfied: polars<2.0.0,>=1.31.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (1.34.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (2.11.9)\n",
      "Requirement already satisfied: pynacl<2.0.0,>=1.5.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (1.5.0)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (0.21.0)\n",
      "Requirement already satisfied: python-multipart<0.0.19,>=0.0.18 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (0.0.18)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=6.0.1 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (6.0.1)\n",
      "Requirement already satisfied: rich==13.7.1 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (13.7.1)\n",
      "Requirement already satisfied: rq in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (2.6.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (0.11.0)\n",
      "Requirement already satisfied: tokenizers in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (0.22.1)\n",
      "Requirement already satisfied: uvicorn<0.30.0,>=0.29.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (0.29.0)\n",
      "Requirement already satisfied: websockets<14.0.0,>=13.1.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from litellm[proxy]) (13.1)\n",
      "Requirement already satisfied: botocore<1.37.0,>=1.36.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from boto3==1.36.0->litellm[proxy]) (1.36.26)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from boto3==1.36.0->litellm[proxy]) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from boto3==1.36.0->litellm[proxy]) (0.11.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from rich==13.7.1->litellm[proxy]) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from rich==13.7.1->litellm[proxy]) (2.15.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from aiohttp>=3.10->litellm[proxy]) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from aiohttp>=3.10->litellm[proxy]) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from aiohttp>=3.10->litellm[proxy]) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from aiohttp>=3.10->litellm[proxy]) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from aiohttp>=3.10->litellm[proxy]) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from aiohttp>=3.10->litellm[proxy]) (1.11.0)\n",
      "Requirement already satisfied: tzlocal>=3.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from apscheduler<4.0.0,>=3.10.4->litellm[proxy]) (5.3.1)\n",
      "Requirement already satisfied: azure-core>=1.31.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from azure-identity<2.0.0,>=1.15.0->litellm[proxy]) (1.35.1)\n",
      "Requirement already satisfied: msal>=1.30.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from azure-identity<2.0.0,>=1.15.0->litellm[proxy]) (1.34.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from azure-identity<2.0.0,>=1.15.0->litellm[proxy]) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from azure-identity<2.0.0,>=1.15.0->litellm[proxy]) (4.15.0)\n",
      "Requirement already satisfied: isodate>=0.6.1 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from azure-storage-blob<13.0.0,>=12.25.1->litellm[proxy]) (0.7.2)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from cryptography->litellm[proxy]) (1.17.1)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from fastapi<0.116.0,>=0.115.5->litellm[proxy]) (0.46.2)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from fastapi-sso<0.17.0,>=0.16.0->litellm[proxy]) (3.3.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from gunicorn<24.0.0,>=23.0.0->litellm[proxy]) (24.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from httpx>=0.23.0->litellm[proxy]) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from httpx>=0.23.0->litellm[proxy]) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from httpx>=0.23.0->litellm[proxy]) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from httpx>=0.23.0->litellm[proxy]) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.23.0->litellm[proxy]) (0.14.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from importlib-metadata>=6.8.0->litellm[proxy]) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jinja2<4.0.0,>=3.1.2->litellm[proxy]) (2.1.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm[proxy]) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm[proxy]) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm[proxy]) (0.10.6)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from mcp<2.0.0,>=1.10.0->litellm[proxy]) (0.4.1)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from mcp<2.0.0,>=1.10.0->litellm[proxy]) (2.11.0)\n",
      "Requirement already satisfied: pywin32>=310 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from mcp<2.0.0,>=1.10.0->litellm[proxy]) (311)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from mcp<2.0.0,>=1.10.0->litellm[proxy]) (3.0.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from openai>=1.99.5->litellm[proxy]) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from openai>=1.99.5->litellm[proxy]) (0.11.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from openai>=1.99.5->litellm[proxy]) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from openai>=1.99.5->litellm[proxy]) (4.66.5)\n",
      "Requirement already satisfied: polars-runtime-32==1.34.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from polars<2.0.0,>=1.31.0->litellm[proxy]) (1.34.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.0->litellm[proxy]) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.0->litellm[proxy]) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.0->litellm[proxy]) (0.4.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from tiktoken>=0.7.0->litellm[proxy]) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from tiktoken>=0.7.0->litellm[proxy]) (2.32.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from click->litellm[proxy]) (0.4.6)\n",
      "Requirement already satisfied: croniter in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from rq->litellm[proxy]) (6.0.0)\n",
      "Requirement already satisfied: redis!=6,>=3.5 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from rq->litellm[proxy]) (6.4.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from tokenizers->litellm[proxy]) (0.35.3)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from azure-core>=1.31.0->azure-identity<2.0.0,>=1.15.0->litellm[proxy]) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from botocore<1.37.0,>=1.36.0->boto3==1.36.0->litellm[proxy]) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from botocore<1.37.0,>=1.36.0->boto3==1.36.0->litellm[proxy]) (2.2.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography->litellm[proxy]) (2.21)\n",
      "Requirement already satisfied: filelock in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm[proxy]) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm[proxy]) (2024.6.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich==13.7.1->litellm[proxy]) (0.1.0)\n",
      "Requirement already satisfied: email-validator>=2.0.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from pydantic[email]>=1.8.0->fastapi-sso<0.17.0,>=0.16.0->litellm[proxy]) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm[proxy]) (3.3.2)\n",
      "Requirement already satisfied: tzdata in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from tzlocal>=3.0->apscheduler<4.0.0,>=3.10.4->litellm[proxy]) (2023.3)\n",
      "Requirement already satisfied: pytz>2021.1 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from croniter->rq->litellm[proxy]) (2024.1)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\arsalan\\anaconda3\\lib\\site-packages (from email-validator>=2.0.0->pydantic[email]>=1.8.0->fastapi-sso<0.17.0,>=0.16.0->litellm[proxy]) (2.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"litellm[proxy]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1946ef77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mcp_chatbot.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mcp_chatbot.py\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from mcp import ClientSession, StdioServerParameters, types\n",
    "from mcp.client.stdio import stdio_client\n",
    "from typing import List, Dict, TypedDict, Any\n",
    "from contextlib import AsyncExitStack\n",
    "import asyncio, json, os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def _flatten_tool_content(content_list) -> str:\n",
    "    \"\"\"Flatten MCP CallToolResult.content into plain text for OpenAI 'tool' message.\"\"\"\n",
    "    parts = []\n",
    "    if isinstance(content_list, list):\n",
    "        for item in content_list:\n",
    "            t = getattr(item, \"type\", None) or (isinstance(item, dict) and item.get(\"type\"))\n",
    "            if t == \"text\":\n",
    "                txt = getattr(item, \"text\", None) or (isinstance(item, dict) and item.get(\"text\"))\n",
    "                if txt is not None:\n",
    "                    parts.append(str(txt))\n",
    "            elif t in (\"json\", \"object\"):\n",
    "                data = (\n",
    "                    getattr(item, \"data\", None)\n",
    "                    or (isinstance(item, dict) and (item.get(\"data\") or item.get(\"value\")))\n",
    "                )\n",
    "                try:\n",
    "                    parts.append(json.dumps(data, ensure_ascii=False))\n",
    "                except Exception:\n",
    "                    parts.append(str(data))\n",
    "            else:\n",
    "                try:\n",
    "                    parts.append(json.dumps(item, default=str, ensure_ascii=False))\n",
    "                except Exception:\n",
    "                    parts.append(str(item))\n",
    "    elif content_list is not None:\n",
    "        if isinstance(content_list, (dict, list)):\n",
    "            parts.append(json.dumps(content_list, ensure_ascii=False))\n",
    "        else:\n",
    "            parts.append(str(content_list))\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "\n",
    "class ToolDefinition(TypedDict):\n",
    "    name: str\n",
    "    description: str\n",
    "    input_schema: dict\n",
    "\n",
    "\n",
    "class MCP_ChatBot:\n",
    "    def __init__(self):\n",
    "        # Point to local proxy by default (LiteLLM on :4000); falls back to OpenAI if you set OPENAI_BASE_URL accordingly\n",
    "        base_url = os.getenv(\"OPENAI_BASE_URL\", \"http://127.0.0.1:4000/v1\")\n",
    "        api_key = os.getenv(\"OPENAI_API_KEY\", \"sk-local\")  # any non-empty string for local proxies\n",
    "        self.model_default = os.getenv(\"LOCAL_MODEL\", \"qwen2.5:1.5b\")\n",
    "\n",
    "        self.client = OpenAI(base_url=base_url, api_key=api_key)\n",
    "        \n",
    "        def print_available_models(client):\n",
    "            try:\n",
    "                resp = client.models.list()\n",
    "                print(\"Models from base_url:\", [m.id for m in resp.data])\n",
    "            except Exception as e:\n",
    "                print(\"Failed to list models:\", e)\n",
    "\n",
    "        self.exit_stack = AsyncExitStack()\n",
    "        self.sessions: List[ClientSession] = []\n",
    "        self.tool_to_session: Dict[str, ClientSession] = {}\n",
    "        self.available_tools: List[ToolDefinition] = []  # OpenAI function-calling schema\n",
    "\n",
    "    def _openai_tools_from_mcp(self, mcp_tools: List[types.Tool]) -> List[dict]:\n",
    "        tools = []\n",
    "        for t in mcp_tools:\n",
    "            tools.append({\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": t.name,\n",
    "                    \"description\": t.description or \"\",\n",
    "                    \"parameters\": t.inputSchema or {\"type\": \"object\", \"properties\": {}},\n",
    "                }\n",
    "            })\n",
    "        return tools\n",
    "\n",
    "    async def connect_to_server(self, server_name: str, server_cfg: dict):\n",
    "        \"\"\"Connect to one MCP server (stdio).\"\"\"\n",
    "        try:\n",
    "            params = StdioServerParameters(**server_cfg)\n",
    "            read, write = await self.exit_stack.enter_async_context(stdio_client(params))\n",
    "            session = await self.exit_stack.enter_async_context(ClientSession(read, write))\n",
    "            await session.initialize()\n",
    "\n",
    "            # Remember the session\n",
    "            self.sessions.append(session)\n",
    "\n",
    "            # Discover tools for this server\n",
    "            resp = await session.list_tools()\n",
    "            tools = resp.tools or []\n",
    "            print(f\"Connected to {server_name} with tools:\", [t.name for t in tools])\n",
    "\n",
    "            # Map tool -> session and add to OpenAI tool list\n",
    "            for t in tools:\n",
    "                self.tool_to_session[t.name] = session\n",
    "            self.available_tools.extend(self._openai_tools_from_mcp(tools))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to connect to {server_name}: {e}\")\n",
    "\n",
    "    async def connect_to_servers(self, config_path: str = \"server_config.json\"):\n",
    "        \"\"\"Read server_config.json and connect to each server.\"\"\"\n",
    "        with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            cfg = json.load(f)\n",
    "        servers = cfg.get(\"mcpServers\", {})\n",
    "        for name, server_cfg in servers.items():\n",
    "            await self.connect_to_server(name, server_cfg)\n",
    "\n",
    "    async def process_query(self, query: str, model: str | None = None):\n",
    "        model = model or self.model_default\n",
    "        messages: List[Dict[str, Any]] = [{\"role\": \"user\", \"content\": query}]\n",
    "\n",
    "        while True:\n",
    "            resp = self.client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                tools=self.available_tools or None,\n",
    "                tool_choice=\"auto\" if self.available_tools else \"none\",\n",
    "                temperature=0.1,\n",
    "            )\n",
    "            msg = resp.choices[0].message\n",
    "\n",
    "            # Tool calls?\n",
    "            if msg.tool_calls:\n",
    "                # Keep assistant msg (with tool_calls) in history\n",
    "                messages.append({\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": msg.content or \"\",\n",
    "                    \"tool_calls\": [tc.model_dump() for tc in msg.tool_calls],\n",
    "                })\n",
    "\n",
    "                for tc in msg.tool_calls:\n",
    "                    tool_name = tc.function.name\n",
    "                    raw_args = tc.function.arguments\n",
    "                    try:\n",
    "                        args = json.loads(raw_args) if isinstance(raw_args, str) else (raw_args or {})\n",
    "                    except Exception:\n",
    "                        args = {}\n",
    "\n",
    "                    session = self.tool_to_session.get(tool_name)\n",
    "                    if not session:\n",
    "                        # Unknown tool — tell the model\n",
    "                        messages.append({\n",
    "                            \"role\": \"tool\",\n",
    "                            \"tool_call_id\": tc.id,\n",
    "                            \"name\": tool_name,\n",
    "                            \"content\": f\"Tool '{tool_name}' is not available.\",\n",
    "                        })\n",
    "                        continue\n",
    "\n",
    "                    print(f\"Calling tool {tool_name} with args {args}\")\n",
    "                    try:\n",
    "                        result = await session.call_tool(tool_name, arguments=args)\n",
    "                        tool_content = _flatten_tool_content(result.content)\n",
    "                    except Exception as e:\n",
    "                        tool_content = f\"Tool '{tool_name}' failed: {e}\"\n",
    "\n",
    "                    messages.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tc.id,\n",
    "                        \"name\": tool_name,\n",
    "                        \"content\": tool_content,\n",
    "                    })\n",
    "\n",
    "                # Let the model read tool results and continue\n",
    "                continue\n",
    "\n",
    "            # Final answer (no tool calls)\n",
    "            if msg.content:\n",
    "                print(msg.content.strip())\n",
    "            break\n",
    "\n",
    "    async def chat_loop(self):\n",
    "        print(\"\\nMCP Chatbot (OpenAI-compatible) — type your query, or 'quit' to exit.\")\n",
    "        print(f\"Using model: {self.model_default}\")\n",
    "        while True:\n",
    "            try:\n",
    "                q = input(\"\\nQuery: \").strip()\n",
    "                if q.lower() == \"quit\":\n",
    "                    break\n",
    "                await self.process_query(q)  # uses self.model_default\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "    async def run(self):\n",
    "        try:\n",
    "            await self.connect_to_servers()\n",
    "            await self.chat_loop()\n",
    "        finally:\n",
    "            await self.exit_stack.aclose()\n",
    "\n",
    "\n",
    "async def main():\n",
    "    bot = MCP_ChatBot()\n",
    "    await bot.run()\n",
    "\n",
    "\n",
    "# Safe runner: works in normal terminals and in environments with an active event loop\n",
    "def _run_async(coro):\n",
    "    try:\n",
    "        loop = asyncio.get_running_loop()\n",
    "    except RuntimeError:\n",
    "        return asyncio.run(coro)\n",
    "    else:\n",
    "        return asyncio.create_task(coro)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    _run_async(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b2fdc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
